{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install necessary libraries\n",
        "!pip install pandas numpy scikit-learn nltk\n",
        "\n",
        "# Step 2: Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import zipfile\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "# Step 3: Load the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\"\n",
        "response = requests.get(url)\n",
        "with zipfile.ZipFile(BytesIO(response.content)) as z:\n",
        "    with z.open('SMSSpamCollection') as f:\n",
        "        df = pd.read_csv(f, sep='\\t', names=['label', 'message'])\n",
        "\n",
        "# Step 4: Preprocess the data\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Tokenize text\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # Remove stop words\n",
        "    words = [word for word in words if word not in stopwords.words('english')]\n",
        "\n",
        "    # Stemming\n",
        "    ps = PorterStemmer()\n",
        "    words = [ps.stem(word) for word in words]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "df['message'] = df['message'].apply(preprocess_text)\n",
        "\n",
        "# Step 5: Feature extraction\n",
        "tfidf = TfidfVectorizer(max_features=3000)\n",
        "X = tfidf.fit_transform(df['message']).toarray()\n",
        "y = df['label'].map({'ham': 0, 'spam': 1}).values\n",
        "\n",
        "# Step 6: Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 7: Train the classifier\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 8: Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 9: Make predictions\n",
        "def predict_sms(text):\n",
        "    text = preprocess_text(text)\n",
        "    text_vec = tfidf.transform([text]).toarray()\n",
        "    prediction = model.predict(text_vec)\n",
        "    return 'spam' if prediction[0] == 1 else 'ham'\n",
        "\n",
        "# Example\n",
        "print(predict_sms(\"Congratulations! You've won a $1000 Walmart gift card. Go to http://bit.ly/123456 to claim now.\"))\n",
        "print(predict_sms(\"Hey, are we still meeting for lunch tomorrow?\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JDA7g-eLQ2U",
        "outputId": "2a4743c2-5d1f-4e9d-a912-91c32b43dcac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9802690582959641\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       966\n",
            "           1       1.00      0.85      0.92       149\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.99      0.93      0.95      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n",
            "spam\n",
            "ham\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "74B64Zrjejcu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}